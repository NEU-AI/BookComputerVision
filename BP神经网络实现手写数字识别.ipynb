{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BP神经网络\n",
    "![](.\\pic\\bpmap.png)\n",
    "上图为BP神经网络的经典网络图。BP神经网络是一种按误差逆传播算法训练的多层前馈网络，是目前应用最广泛的神经网络模型之一。BP网络能学习和存贮大量的输入-输出模式映射关系，而无需事前揭示描述这种映射关系的数学方程。BP神经网络模型拓扑结构包括输入层（input）、隐藏层(hide layer)和输出层(output layer)。\n",
    "\n",
    "前馈网络就是前馈神经网，是最早方形的简单人工神经网络，在前馈神经网络中各个神经元分别属于不同的层，每层的神经元接收前一层神经元的信号，并产生信号输出给下一层。如上图所示。第0层为输入层，最后一层为输出层，中间为隐藏层。隐藏层和上一层的输入层的连接关系通常称为全连接，全连接的意思就是隐藏层的每个神经元和输入层的每个神经元都有链接。\n",
    "\n",
    "隐藏节点做了什么事呢？如下图，做了两步，第一步对输入的值进行加权求和（即输入信号x乘以权重w，再累加），这个权重在机器学习中非常重要，整个机器学习的训练就是为了计算这个权重，通过不断的学习更新这个权重，以达到最后的输出和实际值无限接近，最后在增加一个偏置B。第二步就是使用一个函数把输出的值压缩到0-1之间（sigmod函数就是激活函数，输入的值可以理解为从负无穷到正无穷大之间的值）这个过程也叫做非线性变换。目前最常用的是ReLU激活函数。\n",
    "\n",
    "![](.\\pic\\bpsub2.png)\n",
    "\n",
    "为什么引入这种非线性变换，而不是线性变换。如下图，横坐标表示房子大小，纵坐标表示房子价格，左图的×表示某个房子大小所在的价格，左图的一条直线贯穿这些×，基本是拟合的，可以表示出随着房子增大价格是在增长的，通过未来的某个时间房子的大小预测出价格，这条线就是一个线性，也叫线性回归，回归就是用我们之前的数据去预测出一个未来的值（regression towards the mean,向着中间值回归。意思就是找一条线通过一堆点，让这条线尽可能在这堆点的中间）。但是我们也可以看出随着房子大小的减小，价格出现了负值，我们知道价格是不会是负值的，因此为了代替一条可能会让价格为负值的直线，我们把直线到纵坐标为0时，向左边弯曲，而不直线向下，这就让它最终在零结束，这个函数就可以完全拟合房屋的价格。如下图的右边图像。这就是ReLU激活函数。而房子的大小就相当于上面说的一个输入神经元比如x1。我们可以知道房子价格不仅仅与房子大小有关，还与它周围的环境比如是不是学区房？它是几室几厅的？等等，这些就是其他的输入神经元x2,x3等，这些因素综合起来影响着房屋的价格。这也就对应上前面的神经网络图了。\n",
    "\n",
    "<div style=\"float:left;border:solid 1px 000;margin:2px;\"><img src=\"./pic/linear1.png\"  width=\"400\" height=\"460\" ></div>\n",
    "<div style=\"float:left;border:solid 1px 000;margin:2px;\"><img src=\"./pic/linear2.png\" width=\"400\" height=\"460\" ></div>\n",
    "\n",
    "<div style=\"float:none;clear:both;\">\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "按误差逆传播的意思就是通过正向计算得出最后的输出后（如第一张图的y1,y2就是最后的输出），从输出层开始反向计算每一层的每个单元的误差项，（输出与实际值做比较，得到一个误差值），如果误差值太大，就更新数据重新计算输出，直到误差不再下降或直到输出层的误差小于预设的容忍度为止。综上所述它的学习规则是使用梯度下降法，通过反向传播来不断调整网络的权值和阈值，使网络的误差平方和最小。\n",
    "\n",
    "\n",
    "# MNIST手写体\n",
    "\n",
    "MNIST数据集包含60,000个用于训练的示例和10,000个用于测试的示例。这些数字已经过尺寸标准化并位于图像中心，图像是固定大小(28x28像素)，其值为0到1。为简单起见，每个图像都被平展并转换为784(28 * 28)个特征的一维numpy数组。\n",
    "\n",
    "![](.\\pic\\mnist.jpeg)\n",
    "\n",
    "MNIST数据集包含一下4个文件。\n",
    "* train-labels-idx1-ubyte.gz:训练集标记文件\n",
    "* train-images-idx3-ubyte.gz:训练集图片文件\n",
    "* t10k-labels-idx1-ubyte.gz:测试集标记文件\n",
    "* t10k-images-idx3-ubyte.gz:测试集图片文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "# 载入数据 查看数据集的内容\n",
    "digits = load_digits()\n",
    "print(digits.images.shape)#显示数据集的形状，1797张图片，每个图片是8*8的图片，即64像素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi41LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvSM8oowAACrtJREFUeJzt3d2LXeUZhvH77qi0NtZAa4tkQicQCUjBiYSApIiNWGIVMwc9SEChUsiRktCCaE9M/wFJD4oQoolgqrRRExGrFYxYoU3z4aQ1mRjSMCUTtFFK/ISG6NODWSlRInvt7HetvebJ9YPQ+djM+2zk6lqzZ+31OiIEIKevDXsAAM0hcCAxAgcSI3AgMQIHEiNwIDECBxIjcCAxAgcSu6yJH2qby+MKmDdvXmtrLV68uLW1Pv3009bWOnr0aGtrtS0i3OsxjQSOMpYtW9baWjt37mxtrcnJydbWuuWWW1pbq4s4RQcSI3AgMQIHEiNwIDECBxIjcCAxAgcSI3AgsVqB215l+23bx2w/2PRQAMroGbjtEUm/lXS7pOslrbV9fdODARhcnSP4cknHIuJ4RJyR9LSk1c2OBaCEOoEvkHTivM9nqq8B6LhibzaxvU7SulI/D8Dg6gR+UtLC8z4frb72BRGxWdJmibeLAl1R5xR9r6TrbC+yfYWkNZKeb3YsACX0PIJHxFnb90l6WdKIpMcj4lDjkwEYWK3fwSPiRUkvNjwLgMK4kg1IjMCBxAgcSIzAgcQIHEiMwIHECBxIjMCBxNjZpA/j4+Otrrd79+7W1vrggw9aW2tsbKy1tS51HMGBxAgcSIzAgcQIHEiMwIHECBxIjMCBxAgcSIzAgcTq7GzyuO1Ttt9qYyAA5dQ5gm+TtKrhOQA0oGfgEfG6pP+0MAuAwvgdHEiMrYuAxIoFztZFQPdwig4kVufPZE9J+oukJbZnbP+8+bEAlFBnb7K1bQwCoDxO0YHECBxIjMCBxAgcSIzAgcQIHEiMwIHECBxIjK2L+jAxMdHqegcPHmxtrZ07d7a21sMPP9zaWpc6juBAYgQOJEbgQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRW56aLC23vtn3Y9iHb69sYDMDg6lyLflbSLyPigO2rJO23/UpEHG54NgADqrM32TsRcaD6+CNJU5IWND0YgMH19W4y22OSlkrac4HvsXUR0DG1A7c9T9IzkjZExIdf/j5bFwHdU+tVdNuXazbu7RHxbLMjASilzqvolvSYpKmIeKT5kQCUUucIvkLSPZJW2p6s/v2k4bkAFFBnb7I3JLmFWQAUxpVsQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiTG3mR92LRpU6vrTU9Pt7ZWm89t165dra11qeMIDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kVuemi1+3/TfbB6uti37dxmAABlfnUtX/SloZER9Xt09+w/YfI+KvDc8GYEB1broYkj6uPr28+sfGBsAcUHfjgxHbk5JOSXolIi64dZHtfbb3lR4SwMWpFXhEfBYR45JGJS23/YMLPGZzRCyLiGWlhwRwcfp6FT0iTkvaLWlVM+MAKKnOq+jX2J5fffwNSbdJOtL0YAAGV+dV9GslPWF7RLP/h/D7iHih2bEAlFDnVfS/a3ZPcABzDFeyAYkROJAYgQOJETiQGIEDiRE4kBiBA4kROJCYZ98NWviH2q29nXT+/PltLaUNGza0tpYkTUxMtLbW2NhYyrVOnz7d2lptiwj3egxHcCAxAgcSI3AgMQIHEiNwIDECBxIjcCAxAgcSI3AgsdqBV/dGf9M292MD5oh+juDrJU01NQiA8urubDIq6Q5JW5odB0BJdY/gmyQ9IOnzBmcBUFidjQ/ulHQqIvb3eBx7kwEdU+cIvkLSXbanJT0taaXtJ7/8IPYmA7qnZ+AR8VBEjEbEmKQ1kl6NiLsbnwzAwPg7OJBYnb3J/i8iXpP0WiOTACiOIziQGIEDiRE4kBiBA4kROJAYgQOJETiQGIEDifV1oUsXbdy4sbW11q9f39pabWtzm6TM2wl1DUdwIDECBxIjcCAxAgcSI3AgMQIHEiNwIDECBxIjcCCxWleyVXdU/UjSZ5LOcudUYG7o51LVH0XE+41NAqA4TtGBxOoGHpL+ZHu/7XVNDgSgnLqn6D+MiJO2vyvpFdtHIuL18x9QhU/8QIfUOoJHxMnqf09Jek7S8gs8hq2LgI6ps/ngN21fde5jST+W9FbTgwEYXJ1T9O9Jes72ucf/LiJeanQqAEX0DDwijku6oYVZABTGn8mAxAgcSIzAgcQIHEiMwIHECBxIjMCBxAgcSMwRUf6H2uV/6FcYHx9vaylt27attbUk6YYbcl5ftGvXrtbW2rp1a2trSe0+t4hwr8dwBAcSI3AgMQIHEiNwIDECBxIjcCAxAgcSI3AgMQIHEqsVuO35tnfYPmJ7yvZNTQ8GYHB174v+G0kvRcRPbV8h6coGZwJQSM/AbV8t6WZJP5OkiDgj6UyzYwEooc4p+iJJ70naavtN21uq+6MD6Lg6gV8m6UZJj0bEUkmfSHrwyw+yvc72Ptv7Cs8I4CLVCXxG0kxE7Kk+36HZ4L+ArYuA7ukZeES8K+mE7SXVl26VdLjRqQAUUfdV9Pslba9eQT8u6d7mRgJQSq3AI2JSEqfewBzDlWxAYgQOJEbgQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGJ1L1XtrMnJydbWanMftLbX27hxY2trrV69urW1pqenW1tLandvsjo4ggOJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQGIEDifUM3PYS25Pn/fvQ9oY2hgMwmJ6XqkbE25LGJcn2iKSTkp5reC4ABfR7in6rpH9GxL+aGAZAWf2+2WSNpKcu9A3b6yStG3giAMXUPoJXmx7cJekPF/o+WxcB3dPPKfrtkg5ExL+bGgZAWf0EvlZfcXoOoJtqBV7tB36bpGebHQdASXX3JvtE0rcbngVAYVzJBiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBijojyP9R+T1K/byn9jqT3iw/TDVmfG89reL4fEdf0elAjgV8M2/uyvhMt63PjeXUfp+hAYgQOJNalwDcPe4AGZX1uPK+O68zv4ADK69IRHEBhnQjc9irbb9s+ZvvBYc9Tgu2FtnfbPmz7kO31w56pJNsjtt+0/cKwZynJ9nzbO2wfsT1l+6ZhzzSIoZ+iV/daP6rZO8bMSNoraW1EHB7qYAOyfa2kayPigO2rJO2XNDHXn9c5tn8haZmkb0XEncOepxTbT0j6c0RsqW40emVEnB72XBerC0fw5ZKORcTxiDgj6WlJq4c808Ai4p2IOFB9/JGkKUkLhjtVGbZHJd0hacuwZynJ9tWSbpb0mCRFxJm5HLfUjcAXSDpx3uczShLCObbHJC2VtGe4kxSzSdIDkj4f9iCFLZL0nqSt1a8fW6r7Ec5ZXQg8NdvzJD0jaUNEfDjseQZl+05JpyJi/7BnacBlkm6U9GhELJX0iaQ5/ZpQFwI/KWnheZ+PVl+b82xfrtm4t0dEljvSrpB0l+1pzf46tdL2k8MdqZgZSTMRce5Ma4dmg5+zuhD4XknX2V5UvaixRtLzQ55pYLat2d/lpiLikWHPU0pEPBQRoxExptn/Vq9GxN1DHquIiHhX0gnbS6ov3SppTr8o2u/eZMVFxFnb90l6WdKIpMcj4tCQxyphhaR7JP3D9mT1tV9FxItDnAm93S9pe3WwOS7p3iHPM5Ch/5kMQHO6cIoOoCEEDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiT2PyAejMJD4lXzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 显示图片\n",
    "plt.imshow(digits.images[0],cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(digits.images[1],cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(digits.images[2],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n",
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      "  15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "   0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "   0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n",
      " [ 0.  0.  0. 12. 13.  5.  0.  0.  0.  0.  0. 11. 16.  9.  0.  0.  0.  0.\n",
      "   3. 15. 16.  6.  0.  0.  0.  7. 15. 16. 16.  2.  0.  0.  0.  0.  1. 16.\n",
      "  16.  3.  0.  0.  0.  0.  1. 16. 16.  6.  0.  0.  0.  0.  1. 16. 16.  6.\n",
      "   0.  0.  0.  0.  0. 11. 16. 10.  0.  0.]\n",
      " [ 0.  0.  0.  4. 15. 12.  0.  0.  0.  0.  3. 16. 15. 14.  0.  0.  0.  0.\n",
      "   8. 13.  8. 16.  0.  0.  0.  0.  1.  6. 15. 11.  0.  0.  0.  1.  8. 13.\n",
      "  15.  1.  0.  0.  0.  9. 16. 16.  5.  0.  0.  0.  0.  3. 13. 16. 16. 11.\n",
      "   5.  0.  0.  0.  0.  3. 11. 16.  9.  0.]]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# 查看数据内容\n",
    "X = digits.data\n",
    "# 查看标签\n",
    "y = digits.target\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X[:3])#看前三行的数据\n",
    "print(y[:3])#看前三行标签，可以看出前三个样本是0,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.86363455  0.75472695 -0.47418705 ...  0.28498997 -0.91418357\n",
      "   0.82438333]\n",
      " [ 0.73591496  0.85396157 -0.16606819 ...  0.256474   -0.3874193\n",
      "   0.61418037]\n",
      " [-0.81051746  0.20896592  0.2577596  ... -0.39261648  0.45731187\n",
      "   0.98904883]\n",
      " ...\n",
      " [-0.33903062  0.73251625 -0.36873274 ...  0.82763529 -0.48534643\n",
      "  -0.99886706]\n",
      " [ 0.50122246 -0.40300408 -0.83671298 ...  0.93051072 -0.32113572\n",
      "   0.03476708]\n",
      " [ 0.51834879  0.15514284  0.90650464 ...  0.2616939  -0.95187344\n",
      "   0.62284804]]\n",
      "[[-5.25633370e-01  8.15827754e-01  1.08695715e-01 -1.35780703e-01\n",
      "   9.20802226e-01 -8.61085035e-01  9.50004179e-01 -2.48232182e-01\n",
      "  -9.61833598e-01 -5.02040350e-01]\n",
      " [ 4.56106581e-01  4.76264394e-01 -6.04053932e-01 -4.16258259e-01\n",
      "   8.75204684e-01  2.71813214e-01  1.70214232e-01 -4.61207616e-01\n",
      "   5.44864477e-01  1.27765341e-01]\n",
      " [ 5.18122811e-02 -1.11682631e-01 -3.22222624e-04 -6.35834564e-01\n",
      "  -4.59732066e-01 -8.60160772e-01  5.66864075e-01  1.68350031e-01\n",
      "  -8.59731949e-02  7.64447171e-01]\n",
      " [-4.72054551e-01  9.93399947e-01  2.92352036e-01  8.26828448e-01\n",
      "  -1.13145155e-01  4.30067940e-02 -5.59635244e-01 -6.60404066e-01\n",
      "   6.55314952e-01  8.22074734e-01]\n",
      " [-2.84050632e-01 -6.99797134e-01  8.23082019e-01 -3.06324513e-01\n",
      "  -1.10308694e-01  2.19819293e-01 -3.59029414e-01  2.93653602e-01\n",
      "  -3.20005791e-01 -2.90642004e-01]\n",
      " [ 2.74066808e-01 -1.44928264e-01 -1.23319340e-01  4.59569736e-01\n",
      "  -8.50306272e-01 -5.40544989e-02  6.81239408e-01 -3.57745747e-01\n",
      "   5.88853445e-01  8.31293515e-01]\n",
      " [ 6.07524430e-01  9.81670298e-01  7.30104436e-02  3.69342310e-01\n",
      "  -3.96716400e-01 -2.62801660e-01  9.15494075e-01 -1.72130331e-01\n",
      "   1.53235999e-01 -2.05767114e-02]\n",
      " [ 6.99526686e-01 -2.24410435e-01  8.99390061e-01 -2.30027086e-02\n",
      "  -1.01361554e-01 -8.70659641e-01 -9.63022529e-01  1.55695551e-01\n",
      "   1.99865720e-01 -3.26936655e-01]\n",
      " [-3.91823142e-01 -8.70148991e-01  3.25953705e-01 -5.95717644e-01\n",
      "   3.41695071e-01 -7.88316526e-01 -5.52535571e-01  8.82149814e-01\n",
      "   7.46054591e-01 -7.84216395e-01]\n",
      " [-5.66093452e-01  2.77073529e-02  4.65811578e-01 -6.04352537e-01\n",
      "   4.63403175e-01 -7.24490132e-02 -7.30883167e-01 -8.24844906e-01\n",
      "   3.88772573e-01 -6.10787353e-01]\n",
      " [-4.91759605e-01  8.07251505e-02  1.73417073e-01 -9.92378776e-01\n",
      "  -4.19733056e-01  7.65614317e-01  1.06614019e-01 -8.70513439e-01\n",
      "   2.37697746e-01  6.88309442e-01]\n",
      " [-3.23902725e-02 -9.29014552e-01  5.69747039e-01  1.77919635e-01\n",
      "   3.68255745e-01 -3.57720875e-01  8.22597407e-01  7.95282445e-02\n",
      "  -4.46776586e-01 -1.25752222e-01]\n",
      " [ 4.50227487e-01  2.98708853e-01 -8.38338132e-01 -9.63375203e-01\n",
      "  -1.13569067e-01  2.92402014e-01 -8.56158484e-01  9.47482404e-01\n",
      "   9.03392793e-01 -6.11028450e-01]\n",
      " [-9.86951552e-01 -1.46756122e-01  3.29949001e-01  6.70858495e-01\n",
      "  -4.17324370e-02 -6.73182866e-01  8.49007515e-01  3.47438662e-01\n",
      "   8.27917302e-01 -1.41112120e-01]\n",
      " [-4.53066308e-01  9.45732791e-01  3.94222981e-01  7.31494161e-02\n",
      "  -2.94630094e-01 -6.30132540e-01  2.22474410e-01 -9.27343506e-01\n",
      "   2.35569492e-01 -8.51133875e-01]\n",
      " [-1.27687366e-01 -3.62376473e-01 -7.98798833e-01  8.90963733e-01\n",
      "   2.32589967e-01  2.50871421e-01 -6.06819662e-01  7.54706973e-01\n",
      "  -6.38744884e-01 -6.76309427e-01]\n",
      " [-6.83651891e-01  4.82373521e-01 -5.43994333e-01 -3.10496813e-01\n",
      "  -2.79145767e-01  4.74898143e-01  6.78873873e-01  5.50407612e-01\n",
      "  -2.70731267e-01  4.49783718e-01]\n",
      " [-3.44018758e-01  6.54775943e-01 -3.24543274e-01  6.04977505e-01\n",
      "   7.19106738e-01  2.71780756e-01  8.26751965e-01 -9.22754831e-01\n",
      "   4.77784870e-01  5.39682989e-01]\n",
      " [ 8.36579204e-01 -8.91097982e-01 -4.08401870e-01 -2.88191543e-01\n",
      "   1.97080763e-01  3.86977671e-02  8.57685852e-01  6.03263423e-03\n",
      "   2.72995073e-01  5.63073919e-01]\n",
      " [ 5.86719376e-01 -9.81859503e-01  2.25658957e-01 -7.85822581e-02\n",
      "   1.76847975e-01 -9.73563758e-01  3.40500174e-01  1.05446679e-01\n",
      "   3.30931127e-01  7.69741221e-01]\n",
      " [-7.26191038e-01 -3.25628719e-01  8.98751264e-01 -6.64257614e-02\n",
      "   5.83266358e-01  9.90076580e-01  1.18277759e-01 -4.91688896e-01\n",
      "   6.39293176e-01 -5.14195236e-01]\n",
      " [ 9.31025155e-01  4.82284366e-01 -2.15819103e-03  2.30679337e-01\n",
      "   9.47323877e-01 -3.57084486e-01 -1.74036833e-01  3.30506222e-01\n",
      "  -8.69128443e-01  9.87707962e-01]\n",
      " [ 3.95833584e-01 -2.17462337e-01 -3.96766188e-01  4.46601506e-01\n",
      "  -2.65798176e-01 -2.77931402e-01  9.40988240e-02 -1.88790926e-01\n",
      "   5.19981922e-01 -9.77061358e-01]\n",
      " [ 8.27196239e-01  8.70143704e-01  6.86503639e-01 -2.34786854e-01\n",
      "  -3.53893878e-01 -8.19362638e-01 -1.22665311e-01  8.51057991e-01\n",
      "   7.83411556e-01  3.66372629e-01]\n",
      " [-4.93120913e-01 -5.95610005e-01 -8.03148832e-01 -3.72107044e-01\n",
      "  -9.92016767e-01  3.44663947e-01 -6.93519496e-01  5.58058850e-01\n",
      "  -1.01855925e-01 -4.97149833e-01]\n",
      " [-5.30899270e-01 -9.21726901e-01  1.74508413e-01  3.34327298e-01\n",
      "   4.29566876e-01  8.46179747e-01 -8.24583565e-01  4.70101873e-01\n",
      "  -9.60661736e-01 -2.70149502e-01]\n",
      " [-3.93800180e-02 -2.57022057e-01  6.39213288e-01 -1.19185713e-01\n",
      "   8.29126153e-01 -7.73843236e-01  4.34693480e-01  7.50937518e-01\n",
      "   9.13250282e-01 -9.16265111e-01]\n",
      " [ 6.99857207e-01 -8.61061776e-01  6.96162785e-01 -9.96989288e-02\n",
      "  -3.94346482e-01  9.56184280e-02 -4.24943319e-01  2.94986600e-01\n",
      "  -3.93340412e-02 -2.06673568e-01]\n",
      " [ 5.63332576e-01 -3.27006678e-02 -7.13118511e-01 -3.59770634e-01\n",
      "   8.27082538e-01  3.98264771e-01  1.89872712e-01 -3.91182083e-01\n",
      "   1.60469384e-01 -8.04516176e-01]\n",
      " [ 3.33865219e-01  3.78584338e-01  5.66453453e-01 -5.17568069e-01\n",
      "   3.49321023e-01 -5.55319926e-01 -4.11051552e-01 -8.22384951e-01\n",
      "   8.96326211e-01 -4.39230301e-01]\n",
      " [ 9.64627881e-01  4.43369659e-01 -7.39508002e-01 -6.68741047e-01\n",
      "   9.78978954e-02 -2.49326931e-01 -2.32331302e-01  6.70506453e-01\n",
      "  -6.74620003e-01 -2.83501532e-01]\n",
      " [ 9.39190529e-01 -6.44308666e-01  5.87400102e-01 -5.38664522e-01\n",
      "  -7.75158431e-01 -6.45251512e-01 -7.78220752e-01 -6.63995740e-01\n",
      "   2.86547878e-01 -6.37730272e-01]\n",
      " [-2.89051099e-01  1.38538538e-01  5.84583238e-01 -8.72374406e-01\n",
      "  -8.39594701e-01  7.90246347e-01  1.53228350e-01 -9.64244024e-01\n",
      "   7.90836591e-01  5.38560111e-01]\n",
      " [-8.66527805e-02 -5.53892904e-01 -2.49036501e-02 -2.81503653e-01\n",
      "   2.90247552e-01 -8.02634628e-01  4.23395901e-01 -5.95914925e-01\n",
      "   3.94538348e-01 -6.01921767e-01]\n",
      " [-8.63297610e-01  3.72881609e-01 -4.92605960e-01  5.44429944e-01\n",
      "  -7.55452108e-01  7.83224355e-01  5.57833507e-01 -9.70409008e-01\n",
      "  -9.26079445e-01 -6.92147109e-01]\n",
      " [ 5.64053211e-01 -8.03241412e-01  9.66834331e-01 -8.36766131e-01\n",
      "   8.27180815e-01 -9.96472237e-01 -8.07335551e-01  6.67518205e-01\n",
      "  -7.43524657e-01 -8.68517176e-01]\n",
      " [-1.30388761e-01 -4.86645802e-01  2.60008751e-01 -4.07628477e-01\n",
      "  -7.49092942e-01 -5.76005161e-01 -2.33347608e-01 -1.35618777e-01\n",
      "  -2.10677942e-01 -6.76888185e-01]\n",
      " [-1.88420121e-01 -3.71960017e-01 -9.44001560e-02  3.53996794e-01\n",
      "   1.03142020e-01  5.83025292e-01  1.54810968e-01 -5.58560717e-01\n",
      "  -1.94371808e-01  9.56279084e-01]\n",
      " [ 7.74568768e-01  2.79122077e-01 -1.23275158e-01 -2.10666181e-01\n",
      "  -2.50375209e-01 -5.62027339e-01  6.56017039e-01  7.71351525e-01\n",
      "   1.86971285e-01  8.72410639e-01]\n",
      " [-8.47046234e-01  2.82546368e-01  4.76316384e-01  4.93299357e-01\n",
      "  -3.06288175e-01 -9.13915302e-01  8.77069661e-01 -6.54412435e-01\n",
      "   4.35212961e-01  7.32699731e-01]\n",
      " [-9.55066430e-01 -4.26330399e-01 -5.02167809e-01 -1.02127556e-01\n",
      "   8.07518089e-01  3.26878183e-01  3.27375027e-01  4.66330626e-01\n",
      "   7.25008977e-02 -2.78003585e-01]\n",
      " [-3.89738341e-01 -5.02003641e-01  6.21852298e-01  8.08591225e-01\n",
      "  -5.35737471e-02  1.30609457e-01 -1.13509293e-01 -3.91057524e-01\n",
      "  -3.16353836e-01 -9.83551495e-03]\n",
      " [-4.03452249e-02 -1.16132237e-01  2.94417425e-01 -5.72976912e-01\n",
      "  -8.16196867e-02  2.11856340e-01  6.79995351e-01  7.50627388e-01\n",
      "  -2.13869850e-02 -1.98181440e-01]\n",
      " [ 8.86638379e-01 -4.96204786e-01 -4.17386892e-01  6.28743729e-01\n",
      "  -6.29664118e-01 -1.23825381e-01 -9.41536046e-01 -2.38930303e-01\n",
      "   4.07389928e-01 -8.45459899e-01]\n",
      " [ 6.32884939e-01 -3.10671455e-01  1.71668527e-01  1.75809842e-01\n",
      "   2.01331307e-01  4.36837384e-02 -2.35764250e-01 -8.47598247e-01\n",
      "   6.17720424e-01  6.68882976e-01]\n",
      " [ 5.88020005e-01  2.53154642e-01  4.65322091e-01 -1.54080232e-01\n",
      "  -5.18597798e-01  7.90788783e-01  8.43373433e-01  3.89332868e-01\n",
      "  -1.94309826e-01 -6.70387235e-01]\n",
      " [ 6.35920713e-01 -4.29814968e-01  9.95428455e-01  5.72548627e-01\n",
      "   9.62335555e-02 -5.82195200e-01  9.58593597e-01 -5.17411479e-01\n",
      "   5.97980832e-01 -9.98505261e-01]\n",
      " [-3.24263115e-01 -5.73254763e-01  7.77875420e-01 -9.64860462e-01\n",
      "   8.10795323e-01  3.24892620e-01 -7.66767382e-01  6.64758341e-01\n",
      "   6.19647613e-01 -2.93296077e-01]\n",
      " [-3.82522190e-01  5.25095051e-01 -2.16090517e-01  1.75086521e-01\n",
      "  -8.91566895e-01 -6.30004535e-01  2.52556991e-01 -6.58910872e-01\n",
      "   5.18677964e-01 -4.07208106e-02]\n",
      " [ 6.52767640e-01  9.11260115e-01 -3.12082588e-01  9.97134669e-01\n",
      "   6.71794291e-01 -7.21894685e-01 -7.93113697e-02 -7.51245893e-02\n",
      "   8.32773630e-01 -1.56556299e-01]\n",
      " [-3.46856873e-02  3.13394818e-01 -8.18799440e-01  2.42643929e-01\n",
      "   2.13363814e-01 -3.75614358e-01 -1.52224287e-01  1.68608340e-01\n",
      "   5.43065903e-01  2.23313509e-01]\n",
      " [ 4.45115843e-01  5.33571803e-01  7.69275610e-01  7.79948585e-01\n",
      "   6.67374074e-01  6.56421180e-01 -6.66591225e-01 -7.04057390e-01\n",
      "   5.79049737e-02  7.06841019e-01]\n",
      " [ 4.24218147e-01 -9.71552055e-01  4.04850424e-01  6.34744150e-01\n",
      "  -3.41141524e-01 -7.86218280e-01 -7.18528588e-01  2.62394218e-01\n",
      "  -6.31956322e-01  6.44326489e-01]\n",
      " [ 1.46473505e-01 -8.21117758e-01  7.06468223e-01  5.89883552e-01\n",
      "   9.28383086e-01  4.93745438e-01  1.87281730e-02  8.03517978e-01\n",
      "  -6.89833070e-01 -9.03774959e-01]\n",
      " [-2.76645385e-02  8.63733537e-01  3.53054098e-01 -8.61821993e-01\n",
      "  -5.95878630e-01  9.42488657e-01  1.53632571e-01  5.46344751e-01\n",
      "  -9.69560450e-01  4.64929300e-01]\n",
      " [ 9.61352364e-01  2.86406739e-01  9.06036800e-01  4.94698091e-01\n",
      "  -6.11171785e-01 -6.72740007e-01  3.27535117e-01  2.45554700e-01\n",
      "   4.22614351e-01  7.44478614e-01]\n",
      " [ 9.76814935e-01 -8.66339224e-01  3.09842708e-01  2.30976018e-01\n",
      "  -8.01314359e-01 -6.39683456e-01 -2.02255851e-01 -4.44997875e-01\n",
      "  -3.63673829e-01 -7.66785432e-02]\n",
      " [ 8.08252676e-01 -2.83378140e-01  8.33846982e-01  4.09630874e-01\n",
      "  -5.57456509e-01 -1.73288729e-01  1.13506842e-01  9.40723781e-01\n",
      "  -8.97023392e-01 -1.93192166e-01]\n",
      " [ 8.48117898e-01 -3.33362438e-01  5.11615290e-01  3.72527685e-01\n",
      "   8.04827404e-01  5.78241064e-01 -6.33483612e-01 -3.19264707e-01\n",
      "  -4.33929371e-01  8.29489624e-01]\n",
      " [-5.40284575e-01 -8.79354523e-02 -3.21846790e-01  3.00353679e-01\n",
      "   9.53640730e-01  6.82914424e-01  4.86913204e-02  9.53972147e-01\n",
      "   6.11043716e-01  7.12424469e-01]\n",
      " [-8.83096808e-01 -7.15128738e-01 -3.58887580e-01  1.76047359e-01\n",
      "   9.81967085e-01  4.07488111e-01  5.68238128e-02 -5.04549139e-01\n",
      "   7.52040278e-01 -9.85034635e-01]\n",
      " [-8.67210022e-02 -6.55256932e-02 -4.45488558e-01  5.47809162e-01\n",
      "  -6.08493153e-01  2.35046324e-01  5.97133892e-01 -2.28963331e-01\n",
      "  -7.54490609e-01  1.72574607e-02]\n",
      " [-3.90995473e-02  5.68440837e-01  9.03179736e-01  1.03021904e-02\n",
      "   3.79663621e-01  5.80436057e-01  1.17116372e-01 -3.65638634e-01\n",
      "  -1.63829641e-01 -8.81741201e-01]\n",
      " [ 2.89754099e-01 -1.85115830e-01 -8.92559306e-01 -3.00815115e-01\n",
      "   1.68613464e-01 -5.53190638e-01 -4.78838272e-01 -9.23700232e-01\n",
      "  -4.35207960e-02  8.54040314e-01]\n",
      " [ 9.77912241e-01 -7.72446343e-01 -4.48195347e-02 -7.18256810e-01\n",
      "  -7.22058349e-01  3.69505386e-03 -1.86056043e-03  2.78552335e-01\n",
      "  -5.66383136e-01 -6.63167998e-01]\n",
      " [ 3.14981294e-01 -5.02585479e-01 -7.06337521e-01  2.77471433e-01\n",
      "   4.93117502e-01  9.16188249e-01 -6.19329947e-01 -3.83328552e-02\n",
      "  -1.15376542e-01  3.73065924e-01]\n",
      " [-7.69801355e-01 -1.66980276e-01 -8.32508221e-01  7.91513149e-01\n",
      "  -4.76686854e-02 -9.18682197e-01  9.60574959e-01  1.74800781e-01\n",
      "   6.00145717e-01 -2.04457343e-01]\n",
      " [ 1.59725642e-01  2.31673841e-01  9.46523273e-01  7.24515895e-01\n",
      "   2.48412875e-01  1.17604295e-01 -3.50422733e-01  5.53738176e-02\n",
      "   5.89123078e-01 -4.80842451e-03]\n",
      " [-8.10125735e-01 -1.16807565e-01  9.91956669e-01  3.40460377e-01\n",
      "   5.03108999e-01  8.59234369e-01  2.33627500e-01 -9.32894384e-01\n",
      "  -2.12413038e-01 -6.60525254e-01]\n",
      " [ 5.01470242e-02  2.37209582e-01  7.83611923e-01  3.21859163e-01\n",
      "   3.01235610e-01  9.26855082e-01  9.95957974e-01 -1.25290388e-01\n",
      "  -2.03567183e-01  3.20413767e-01]\n",
      " [ 8.58550019e-01  7.70916240e-01  2.22278712e-01 -2.09811247e-01\n",
      "   8.02395741e-01  2.56467409e-01 -5.23926120e-01  5.90579480e-01\n",
      "   7.17567545e-02  1.31293256e-01]\n",
      " [ 2.85030372e-01  9.63079550e-01 -2.79480483e-01  8.05786314e-01\n",
      "   3.11459746e-02 -8.29213347e-01 -6.23015396e-01  8.93418446e-01\n",
      "  -8.84461447e-01  1.59502416e-01]\n",
      " [-5.09377825e-01  3.17974036e-01 -2.04076645e-01  8.86460001e-01\n",
      "  -5.85501263e-01  4.52696695e-01  3.39825259e-01 -3.78764450e-01\n",
      "  -9.60417656e-01 -1.63056834e-01]\n",
      " [-6.79295386e-01 -6.84960701e-02 -3.29552483e-01 -9.51765566e-01\n",
      "  -5.08421644e-01  4.91008229e-02 -2.47955902e-02  9.57392628e-01\n",
      "  -7.76507520e-01  3.69991766e-01]\n",
      " [ 6.48092065e-01  9.46091059e-01 -8.19420513e-01 -4.24082716e-01\n",
      "   5.16589761e-01 -7.94081452e-01 -5.76036600e-01  9.27349282e-01\n",
      "   9.12890206e-01 -7.45229362e-02]\n",
      " [ 5.76189332e-02  5.87581500e-01 -1.75455291e-02 -9.53660071e-01\n",
      "  -3.14162119e-01  1.78520228e-01  8.81522333e-01 -6.43991562e-01\n",
      "  -1.36358107e-01  4.06350407e-01]\n",
      " [ 7.32044620e-01 -3.84813656e-01 -9.33153043e-01  7.94337936e-01\n",
      "   3.73644787e-01 -2.67853731e-01  8.54089292e-01  7.02110009e-01\n",
      "  -8.52490352e-01  8.06753154e-01]\n",
      " [ 9.71568091e-01  9.03887785e-01  4.22712801e-01 -9.46359451e-01\n",
      "   5.85675683e-01  9.17353440e-02  4.87061447e-01 -7.95872050e-01\n",
      "   7.18057345e-01 -3.39634252e-01]\n",
      " [-7.25877789e-01 -4.37103647e-01 -4.21369204e-01  3.22905535e-01\n",
      "  -7.68665068e-02 -8.57306397e-01 -5.73537459e-01  2.45483388e-01\n",
      "   4.26206187e-01  5.38349356e-01]\n",
      " [ 5.69091160e-01  4.37975995e-01  9.23740222e-01 -3.33430581e-01\n",
      "  -2.60988886e-01  8.65642444e-01  5.57951116e-01 -8.00748064e-01\n",
      "  -4.28536812e-01  8.62714923e-01]\n",
      " [ 2.03850879e-01 -2.08539884e-01  7.42907934e-01 -1.25174337e-01\n",
      "  -4.53302679e-01 -3.13786638e-01 -6.30978673e-01  5.68576371e-01\n",
      "  -2.65604886e-01  4.51688289e-01]\n",
      " [ 8.46794316e-01  7.41630372e-01 -8.75820992e-01 -8.84624427e-01\n",
      "   5.71973988e-01 -6.60429865e-01  7.73617630e-01 -4.70501016e-01\n",
      "  -2.63418920e-01 -1.49091569e-01]\n",
      " [-6.96246964e-02 -5.94193261e-01  3.93143727e-01 -9.74244243e-01\n",
      "  -6.86782393e-01  2.85908228e-01  9.16777691e-01  8.27655636e-01\n",
      "   7.47733246e-01 -4.93084818e-01]\n",
      " [-1.84880320e-01 -8.82235608e-01 -3.77453635e-01  5.20185730e-01\n",
      "   3.99429743e-01 -1.54816993e-01  5.37214043e-01  7.04317726e-01\n",
      "  -2.67307977e-01  7.37299085e-01]\n",
      " [ 7.30135293e-01 -8.87559556e-01 -9.83755411e-01  2.54099975e-01\n",
      "  -1.07192929e-01 -1.86419538e-01  9.67618276e-01 -6.90989840e-02\n",
      "  -9.76659097e-02  7.04160848e-01]\n",
      " [ 5.98063982e-02  3.64309444e-03 -2.84777074e-01  8.23380058e-02\n",
      "  -7.99514250e-02  4.55482870e-03  4.28940510e-01 -8.49769656e-01\n",
      "  -9.34562680e-01 -5.44025376e-01]\n",
      " [ 8.18765646e-01 -9.54654129e-01 -8.98321251e-01  4.03940767e-01\n",
      "  -2.53961409e-01  3.34145465e-01  9.64569471e-01 -6.54817125e-01\n",
      "  -7.67912014e-01 -8.60078460e-01]\n",
      " [-1.01784635e-01 -5.41432255e-01  8.15700402e-01 -9.92879611e-01\n",
      "  -8.00266955e-01 -3.20988754e-01 -4.48432068e-01  7.67511213e-01\n",
      "  -8.47445183e-01  9.15901583e-01]\n",
      " [-4.77996580e-01  5.31476029e-01  6.76073399e-01  3.15317812e-01\n",
      "   6.27271114e-01 -3.17558680e-01  8.18251092e-01 -4.90536524e-01\n",
      "   9.25465963e-01  2.09661994e-03]\n",
      " [ 9.21223312e-01 -2.04592133e-01  6.04555622e-01 -7.40867305e-02\n",
      "  -2.41332659e-01  2.87244115e-01 -9.89254810e-01 -1.25344775e-02\n",
      "   6.38342308e-01 -4.00242439e-01]\n",
      " [-3.34258874e-01  3.28048479e-01 -8.06147402e-01  7.27323583e-01\n",
      "  -2.32055108e-01  4.21367463e-01  2.89711215e-01 -7.31149991e-01\n",
      "   9.57070949e-01 -9.46938219e-01]\n",
      " [-1.76165068e-01  4.03654139e-01 -6.36194983e-01 -4.36760610e-01\n",
      "  -3.99211659e-01 -1.32101050e-01 -8.14471459e-01  4.19536393e-01\n",
      "   9.87408357e-01 -5.06861740e-01]\n",
      " [ 6.40776285e-01  6.60140487e-03  7.78487290e-02 -3.08196272e-01\n",
      "  -6.98382615e-01  1.92881916e-01 -9.19225973e-01 -4.16559647e-01\n",
      "  -4.74987922e-01  6.79199709e-01]\n",
      " [-2.28455276e-01  9.24994460e-01 -4.56466123e-01  9.36069840e-02\n",
      "   6.68573163e-01  8.24567927e-01 -9.34165384e-01 -2.41043102e-02\n",
      "   1.81686289e-01  6.08902216e-01]\n",
      " [ 9.84444607e-01  2.74786042e-01  7.88965614e-02 -6.07070657e-01\n",
      "   7.10165883e-01 -2.29633427e-01 -6.22919422e-01 -8.82650620e-02\n",
      "   2.21173940e-01 -2.26473976e-01]\n",
      " [-9.06905085e-01  7.56437827e-01 -5.75006518e-01  1.04904920e-01\n",
      "   4.66502347e-01 -3.18126104e-01  2.88863207e-01 -6.86759987e-01\n",
      "   5.81099169e-01 -1.82644188e-01]\n",
      " [ 2.61473669e-01 -5.77977646e-01  5.35029885e-02  7.86157785e-01\n",
      "   6.77785049e-01 -6.61132998e-01  4.56979201e-01 -2.64212016e-01\n",
      "  -6.05750167e-01 -5.11452545e-01]\n",
      " [ 9.79055120e-01 -2.21856058e-01 -2.66338292e-01  1.88361774e-01\n",
      "  -7.97726570e-01  2.59821426e-01  2.41884691e-02  1.96536727e-01\n",
      "  -7.93247871e-01  9.83427506e-01]\n",
      " [ 1.92188250e-01 -9.09039223e-01  6.61103599e-01 -8.06967712e-01\n",
      "  -9.20188418e-01 -8.42622200e-01  7.39049538e-01  4.18518195e-01\n",
      "   3.25488957e-01 -1.00507161e-01]\n",
      " [-7.33401248e-01 -9.40899670e-01 -5.70731949e-01  8.86387077e-01\n",
      "   9.87068327e-01  4.21808761e-01  6.47125359e-03 -9.93108345e-01\n",
      "   7.89877640e-01 -7.32498565e-01]]\n",
      "[0 8 2 6 4]\n",
      "[[1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 定义一个神经网络，结构：64-100-10 表示输入是64个神经元（因为每个样本有64个数据如上打印的X.shape可以看出它的长度是64，中间隐藏层\n",
    "#可以任意设置，一般会设置比输入层多，这里100，最后输出定义10个神经元，表示初始0-9的数字。\n",
    "# 因为是三层所以会有两个权值矩阵，定义输入层到隐藏层之间的权值矩阵，大小的定义和网络结构有关，就是它左边有多少个和右边有多少个，输入层\n",
    "#到隐藏层，左边输入层有64个行，右边隐藏层有100列个所以如下定义为(64,100),取值范围可以设置为-1到1之间，默认random是0到1，乘以2就是\n",
    "#从0到2之间，再减去就为-1到1之间。\n",
    "V = np.random.random((64,100))*2-1\n",
    "# 定义隐藏层到输出层之间的权值矩阵，同上。\n",
    "W = np.random.random((100,10))*2-1\n",
    "\n",
    "print(V)\n",
    "print(W)\n",
    "# 数据切分\n",
    "# 默认1/4为测试集，3/4为训练集，X_train训练集数据，X_test测试集数据，y_train训练集标签，y_test测试集标签\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "# 标签二值化即转化成one hot格式 需要为其每一个标签重新构造1*10的数组，其中下标为标签值的地方值为1，原因是为了与我们神经网络10的输出节点相对应\n",
    "# 而且数字是0-9正好是10个数，每个数字对应与一个位置，对于分类问题通常都使用标签二值化处理，这样容易区分每个分类，比如标签是\n",
    "# “yes”，“no”，“yes”处理后就变成1,0,1，更容易去区分。\n",
    "# 0->1000000000\n",
    "# 3->0001000000\n",
    "# 9->0000000001\n",
    "labels_train = LabelBinarizer().fit_transform(y_train)\n",
    "print(y_train[:5])\n",
    "print(labels_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 激活函数\n",
    "\n",
    "激活函数的用途（为什么需要激活函数）？\n",
    "\n",
    "如果不用激活函数（其实相当于激活函数是y = x是线性的），在这种情况下你每一层神经元的输入都是上层输出的线性函数，很容易验证，无论你神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相同。正因为这个的原因，我们决定引入非线性函数作为激活函数，这样深层神经网络表达能力就更加强。\n",
    "有哪些激活函数，早期研究神经网络主要采用sigmoid函数或者tanh函数，但现在流行使用ReLU函数。就是上面说的那个激活函数。原因是sigmoid函数或者tanh函数在深度神经网络中梯度反向传递时导致梯度消失。如果神经网络隐层特别多时，梯度在穿过多层后将变得非常小接近于0，即出现梯度消失现象。\n",
    "\n",
    "![...](.\\pic\\jihuo1.png)\n",
    "![...](.\\pic\\relu.png)\n",
    "\n",
    "\n",
    "# 激活函数导数\n",
    "\n",
    "梯度是什么，前面我们已经讲了从前往后的正向传播就算一个输出，这个输出如果与实际值的误差较大，我们就要调整误差尽量让误差保持在一个能够接受的范围，也就是尽量让误差最小。最后就变成了在误差函数中找最小值，这就要用到梯度下降法。\n",
    "\n",
    "如下图所示对于一个可导的函数，从任意一点出发，沿着导数下降的方向前进直到接近最低点就是导数为零时，就是函数的最小值，就是梯度下降法。通俗的讲就是如果你在山顶，想到山底（最小值），只需要每一步都往下走，不断地走肯定能走到最小值的地方。但是你需要更快地到达最小值，就需要找到每一步下坡最快的地方，即每一步都走某个方向，这个方向比其他方向离最小值更近。而下这个坡最快的方向就是梯度的负方向。\n",
    "\n",
    "![](.\\pic\\td.png)\n",
    "\n",
    "## 导数\n",
    "\n",
    "![](.\\pic\\daoshu2.jpg)\n",
    "\n",
    "设有曲线C及上的一点M，在点M外另取C上一点N，作割线.当点N沿曲线C趋于点M时，如果割线MN绕点N旋转而趋于极限位置MT,直线MT就称为曲线C在点M处的切线.这里极限位置的含义是：只要弦长MN趋于零.\n",
    "\n",
    "现在就曲线C为函数y=f(x)的图形的情形来讨论切线问题.设$M(x_0,y_0)$是曲线C上的一个点，则$y_0=f(x_0)$.根据上述定义要定出曲线C在点M处的切线，只要定出切线的斜率就行了.为此，在点M外另取C上的一点N，于是割线的斜率为$tan(\\phi)=\\frac{y-y_0}{x-x_0}$\n",
    "\n",
    "，\n",
    "\n",
    "其中$\\phi$为割线MN的倾角.当点N沿曲线C趋于点M时，$x \\rightarrow x_0$.如果当$x \\rightarrow x_0$时，上式的极限存在，设为k,即 \n",
    "\n",
    "$\\displaystyle k = \\lim^{}_{x \\to x_0}{\\frac{f(x)-f(x_0)}{x-x_0}}$ 存在，则此极限是割线斜率的极限，也就是切线的斜率，这就是导数通常用dy/dx表示。也可以理解为一元函数的变化率。\n",
    "\n",
    "* 斜率上倾，导数为正数\n",
    "* 斜率下倾，导数为负数\n",
    "* 斜率为水平直线，导数为零\n",
    "\n",
    "\n",
    "## 偏导数\n",
    "\n",
    "### x方向的偏导\n",
    "设有二元函数 $z=f(x,y)$ ，点$(x_0,y_0)$是其定义域内的一点。把 固定在$y_0$而让x在$x_0$有增量 $\\Delta x$ ，相应地函数 $z=f(x,y)$ 有增量（称为对 x 的偏增量）$\\Delta z=f(x_0+\\Delta x,y_0)-f(x_0,y_0)$。\n",
    "如果 $\\Delta z$ 与 $\\Delta x$ 之比当 $\\Delta x \\rightarrow 0$ 时的极限存在，那么此极限值称为函数 $z=f(x,y)$ 在 $(x_0,y_0)$处对 x 的偏导数，记作 $f'_x(x_0,y_0)$或函数 $z=f(x,y)$ 在$(x_0,y_0)$处对 x 的偏导数，实际上就是把 y 固定在 $y_0$看成常数后，一元函数$z=f(x,y_0)$在 $x_0$处的导数或者$\\frac{\\partial z} {\\partial x}$。\n",
    "\n",
    "### y方向的偏导\n",
    "同样，把 x 固定在 $x_0$，让 y 有增量 $\\Delta y $，如果极限存在那么此极限称为函数 $z=(x,y)$ 在 $(x_0,y_0)$处对 y 的偏导数。记作$f'_y(x_0,y_0)$或者$\\frac{\\partial z} {\\partial y}$。\n",
    "\n",
    "所以偏导数是指多变量函数很对某个变量的变化率。常量的变化率为零。即常量求导和求偏导数是零。\n",
    "\n",
    "## 方向导数\n",
    "\n",
    "偏导数$\\frac{\\partial z} {\\partial x}$和$\\frac{\\partial z} {\\partial y}$只是函数沿相应的坐标轴x和y方向的变化率，方向导数就是函数在各个方向上的导数。\n",
    "\n",
    "\n",
    "## 梯度\n",
    "\n",
    "梯度是一个向量（指具有大小和方向的量，它可以形象化地表示为带箭头的线段），其方向上的方向导数最大，其大小正好是此最大方向导数。\n",
    "\n",
    "\n",
    "## 向量\n",
    "\n",
    "向量是一个有方向的线段，它的起点总是原点。向量的表示方式如下：\n",
    "\n",
    "![](.\\pic\\vector1.png)\n",
    "\n",
    "在2维空间中，向量 $\\left[ \\begin{matrix} i \\\\ j \\end{matrix} \\right]$第 1 个数字 i 是尖端落在 x 轴的长度，第 2 个数字 j 是尖端落在 y 轴的长度，如果落在原点的左边（x 轴）和下边（y 轴），则 i、j 的值为负数；在 3 维空间中，每个向量有 3 个数（i、j、k）来表示，分别是尖端落在 x、y、z 轴上的长度，x、y、z 同样是有符号的。如下图。\n",
    "\n",
    "![](.\\pic\\vector2.png)\n",
    "\n",
    "### 向量相加\n",
    "\n",
    "向量 $\\vec v （\\left[\\begin{matrix}2\\\\4\\end{matrix}\\right]）$和向量 $\\vec w （\\left[\\begin{matrix}3\\\\1\\end{matrix}\\right]）$相加的示意图如下\n",
    "\n",
    "![](.\\pic\\vector3.png)\n",
    "\n",
    "*    保持 $\\vec v$ 不动\n",
    "*    保持 $\\vec w$ 的方向不变，将 $\\vec w$ 的末端平行移动到移动到 $\\vec v$ 的尖端\n",
    "*    从原点到$\\vec w$ 尖端的向量即为 $\\vec v$ 和 $\\vec w$ 的和     \n",
    "\n",
    "$\\left[ \\begin{matrix} 2 \\\\ 4 \\end{matrix} \\right] + \\left[ \\begin{matrix} 3 \\\\ 1 \\end{matrix} \\right] = \\left[ \\begin{matrix} 2 + 3 \\\\ 4 + 1 \\end{matrix} \\right]$\n",
    "\n",
    "### 向量和常量乘法\n",
    "\n",
    "用一个常量乘上一个向量，意味着将向量保持在其所在的直线上，对其长度进行拉伸、压缩和反向操作，例如 $2\\vec v $是将向量$ \\vec v $的长度拉升为原来的 2 倍，$\\frac{1}{3} \\vec v $是将$ \\vec v $压缩为原来的$ \\frac{1}{3}$，$-1.8 \\vec v $是先对$ \\vec v$ 进行反向，再将其长度拉伸为原来的 1.8 倍。\n",
    "$\\left[ \\begin{matrix} 2\\\\ 4 \\end{matrix} \\right] \\times 2 = \\left[ \\begin{matrix} 2 \\times 2\\\\ 2 \\times 4 \\end{matrix} \\right]$\n",
    "\n",
    "![](.\\pic\\vector4.png)\n",
    "\n",
    "\n",
    "## 矩阵\n",
    "\n",
    "矩阵的本质其实是一种线性变换，线性方程式的简化表示方式，两者是一一对应关系。看如下所示。\n",
    "\n",
    "$A= \\left\\{ \\begin{array} \\\\2x +y=3\\\\ 3x+4y=7  \\end{array} \\right\\}$\n",
    "\n",
    "$\\left[ \\begin{matrix}  2 & 1 \\\\ 3 & 4  \\end{matrix} \\right] \\left[ \\begin{matrix} x \\\\ y  \\end{matrix} \\right] = \\left[ \\begin{matrix}  2x +y \\\\ 3x+4y  \\end{matrix} \\right] = \\left[ \\begin{matrix}  3 \\\\ 7  \\end{matrix} \\right]$\n",
    "\n",
    "向量（列向量）$（\\left[\\begin{matrix}x\\\\y\\end{matrix}\\right]）$左侧就是2\\*2的矩阵。它是$（\\left[\\begin{matrix}2\\\\3\\end{matrix}\\right]）$和$（\\left[\\begin{matrix}1\\\\4\\end{matrix}\\right]）$向量的组合，矩阵与向量的乘法运算法则也就如图所示。\n",
    "\n",
    "![](.\\pic\\juzhen1.png)\n",
    "\n",
    "通过上述可以理解如下两个矩阵的乘法规则：\n",
    "\n",
    "![](.\\pic\\juzhen2.png)\n",
    "![](.\\pic\\juzhen3.png)\n",
    "![](.\\pic\\juzhen4.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 激活函数\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# 激活函数的导数\n",
    "def dsigmoid(x):\n",
    "    return x*(1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BP算法如下图\n",
    "![](.\\pic\\bp1.png)\n",
    "\n",
    "上述公式只要了解一下就可以。\n",
    "\n",
    "E代表损失函数，通过梯度下降法来最小化损失函数，所以就需要对损失函数的W权重求导。y=f(WX)是激活函数，算出预测值。t是标签。X是输入信号是已知的，W权重是需要调整的，用来减少误差，所以对它求导。当前使用的是二次损失函数。它的求导属于复合函数求导可以得出图中的式子，其中需要注意的就是W和X都是矩阵，所以f(WX)求导得出的是X的转置矩阵（行列交换的结果矩阵）。梯度下降法的公式就是负学习率$\\eta$（0-1之间）乘以E的求导结果,把这个作为权重的变化，如上图最右侧的结果。\n",
    "\n",
    "$ E' = 2 \\times \\frac{1}{2} \\times (t-f(WX)) \\times [t-f(WX)]'=(t-f(WX)) \\times -f'(WX) \\times (WX)' = - (X^T)\\times(t-f(WX))\\times f'(WX) $\n",
    "\n",
    "$\\delta = (t-f(WX))\\times f'(WX)$\n",
    "\n",
    "\n",
    "![矩阵求导](.\\pic\\vector5.png)\n",
    "\n",
    "最下方的公式是BP算法的最后结论，直接使用即可。其中$\\delta ^ L$里的参数都是已知的，可以直接计算出结果，用在$\\delta ^ l$的计算公式里，根据公式可以看出只有先知道了最后一层结果才能推算前一层的结果，这就是一个反向求解的过程。最后结论的求解过程可以参考《人工神经网络理论设计与应用第2版》中“第3.2.2.2 BP算法推论”了解。实际可以直接使用结论即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 训练模型X 是训练集数据，y是标签集，steps我们训练的次数，lr是learningrate学习率\n",
    "def train(X,y,steps=10000,lr=0.11):\n",
    "    global V,W\n",
    "    for n in range(steps+1):\n",
    "        # 随机选取一个数据\n",
    "        i = np.random.randint(X.shape[0])\n",
    "        # 获取一个数据\n",
    "        x = X[i]\n",
    "        x = np.atleast_2d(x)# 数据转成二维数组，矩阵乘法计算时需要用二维数组，原数据是一维数组\n",
    "        # BP算法公式\n",
    "        # 计算隐藏层的输出\n",
    "        L1 = sigmoid(np.dot(x,V))#矩阵乘法x*V\n",
    "        # 计算输出的输出\n",
    "        L2 = sigmoid(np.dot(L1,W))\n",
    "        # 计算L2_delta，L1_delta\n",
    "        L2_delta = (y[i]-L2)*dsigmoid(L2)\n",
    "        L1_delta = L2_delta.dot(W.T)*dsigmoid(L1)\n",
    "        # 更新权值\n",
    "        W += lr*L1.T.dot(L2_delta)\n",
    "        V += lr*x.T.dot(L1_delta)\n",
    "        \n",
    "        # 每训练1000次预测一次准确率\n",
    "        if n%1000==0:\n",
    "            output = predict(X_test)#把测试集数据输入得到预测值\n",
    "            predictions = np.argmax(output,axis=1)#数据是一个长度10的一维数组，最大值就是1,1所在的位置就是对应的数字。\n",
    "            #求平均值，判断预测值和测试集的标签是不是相等，比如与测试是1，测试集是\"[1,1,1,1,1,8,2,3,4,5]\",那么equal返回\n",
    "            #的是[true,true,true,true,true,false,false,false,false,false]再使用mean后就是0.5，即准确率是0.5\n",
    "            acc = np.mean(np.equal(predictions,y_test))\n",
    "            print('steps:',n,'accuracy:',acc)\n",
    "\n",
    "def predict(x):\n",
    "    # 计算隐藏层的输出\n",
    "    L1 = sigmoid(np.dot(x,V))\n",
    "    # 计算输出的输出\n",
    "    L2 = sigmoid(np.dot(L1,W))\n",
    "    return L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: 0 accuracy: 0.08444444444444445\n",
      "steps: 1000 accuracy: 0.52\n",
      "steps: 2000 accuracy: 0.64\n",
      "steps: 3000 accuracy: 0.7222222222222222\n",
      "steps: 4000 accuracy: 0.7955555555555556\n",
      "steps: 5000 accuracy: 0.8266666666666667\n",
      "steps: 6000 accuracy: 0.84\n",
      "steps: 7000 accuracy: 0.8444444444444444\n",
      "steps: 8000 accuracy: 0.8555555555555555\n",
      "steps: 9000 accuracy: 0.8577777777777778\n",
      "steps: 10000 accuracy: 0.9488888888888889\n",
      "steps: 11000 accuracy: 0.94\n",
      "steps: 12000 accuracy: 0.9444444444444444\n",
      "steps: 13000 accuracy: 0.9622222222222222\n",
      "steps: 14000 accuracy: 0.9755555555555555\n",
      "steps: 15000 accuracy: 0.9511111111111111\n",
      "steps: 16000 accuracy: 0.9688888888888889\n",
      "steps: 17000 accuracy: 0.9711111111111111\n",
      "steps: 18000 accuracy: 0.9688888888888889\n",
      "steps: 19000 accuracy: 0.9755555555555555\n",
      "steps: 20000 accuracy: 0.9688888888888889\n",
      "steps: 21000 accuracy: 0.9622222222222222\n",
      "steps: 22000 accuracy: 0.9666666666666667\n",
      "steps: 23000 accuracy: 0.9688888888888889\n",
      "steps: 24000 accuracy: 0.9755555555555555\n",
      "steps: 25000 accuracy: 0.9733333333333334\n",
      "steps: 26000 accuracy: 0.9733333333333334\n",
      "steps: 27000 accuracy: 0.98\n",
      "steps: 28000 accuracy: 0.9711111111111111\n",
      "steps: 29000 accuracy: 0.9644444444444444\n",
      "steps: 30000 accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "train(X_train,labels_train,30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        43\n",
      "          1       1.00      0.94      0.97        48\n",
      "          2       1.00      0.98      0.99        54\n",
      "          3       0.95      0.98      0.97        43\n",
      "          4       0.96      1.00      0.98        43\n",
      "          5       1.00      0.98      0.99        48\n",
      "          6       1.00      0.98      0.99        41\n",
      "          7       1.00      0.98      0.99        53\n",
      "          8       0.89      0.98      0.93        43\n",
      "          9       1.00      1.00      1.00        34\n",
      "\n",
      "avg / total       0.98      0.98      0.98       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = predict(X_test)\n",
    "predictions = np.argmax(output,axis=1)\n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
